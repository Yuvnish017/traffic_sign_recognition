{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Retraining_functions.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "c6L9vOUTZMY0",
        "R2VLHYUBXxHM",
        "zd5gHmOZX8h5",
        "dZYnzRg0YHL8",
        "FUjDi_goYPvR",
        "U7sbxxfyYY2N"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4qQqjbMPe83"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import csv\n",
        "from keras.utils import to_categorical\n",
        "import keras\n",
        "from keras.layers import Input, Conv2D, Activation, MaxPool2D, Flatten, Dense, BatchNormalization, Dropout, InputLayer\n",
        "from keras.models import Model, Sequential\n",
        "from keras import backend as K\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import pickle \n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from keras.models import load_model "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6L9vOUTZMY0"
      },
      "source": [
        "# Functions for Data Input\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HyxQadhaM3_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52a8c04b-02d1-4b91-93db-be445f5ab2e5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLdGBsJOaX9X"
      },
      "source": [
        "# contains images to be trained in csv format\n",
        "train_path = '/content/drive/MyDrive/images_color.csv'\n",
        "\n",
        "# contains images to be tested in csv format\n",
        "test_path = '/content/drive/MyDrive/test_set_in_csv.csv'"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw3qdceDaD3G"
      },
      "source": [
        "# function that inputs training data and returns test data and labels in proper shape\n",
        "def load_train_data():\n",
        "  '''\n",
        "  function: loads training data from drive\n",
        "  param:\n",
        "  returns: training data and corresponding labels in proper shape\n",
        "  '''\n",
        "  X_train = []\n",
        "  Y_train = []\n",
        "  img_size = 32\n",
        "  channels = 3\n",
        "  num_classes = 43\n",
        "\n",
        "  with open(train_path, 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for row in reader:\n",
        "      if row[0]!='':\n",
        "        label = row[0]\n",
        "        image = np.array([int(a) for a in row[1:]], dtype='uint8')\n",
        "        image = image.reshape((img_size, img_size, channels))\n",
        "        X_train.append(image)\n",
        "        Y_train.append(label)\n",
        "\n",
        "  X_train = np.array(X_train)\n",
        "  Y_train = np.array(Y_train)\n",
        "\n",
        "  Y_train = to_categorical(Y_train)\n",
        "\n",
        "  return X_train, Y_train"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lgfT95AaD86"
      },
      "source": [
        "# function that inputs testing data and returns test data and it's labels in proper shape\n",
        "def load_test_data():\n",
        "  '''\n",
        "  function: loads testing data from drive\n",
        "  param:\n",
        "  returns: testing data and corresponding labels in proper shape\n",
        "  '''\n",
        "  X_test = []\n",
        "  Y_test = []\n",
        "\n",
        "  with open(test_path, 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    header = next(reader)\n",
        "    for row in reader:\n",
        "      if len(row)!=0:\n",
        "        label = row[0]\n",
        "        image = np.array([int(a) for a in row[1:]], dtype='uint8')\n",
        "        image = image.reshape((32, 32, 3))\n",
        "        X_test.append(image)\n",
        "        Y_test.append(label)\n",
        "\n",
        "  X_test = np.array(X_test)\n",
        "  Y_test = np.array(Y_test)\n",
        "\n",
        "  Y_test = to_categorical(Y_test)\n",
        "  \n",
        "  return X_test, Y_test"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olV0QGbaXhWJ"
      },
      "source": [
        "# Function to Design CNN + softmax layer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4QdxG6NuxWh"
      },
      "source": [
        "# defines the types of layers and optimizers that are available to design CNN architecture\n",
        "layers = ['Conv2D', 'MaxPool2D', 'Flatten', 'Dense', 'BatchNormalization', 'Dropout']\n",
        "optimizers = ['SGD', 'RMSprop', 'Adam']"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAFgGpuZux1P"
      },
      "source": [
        "# path in drive where the trained models gets saved\n",
        "model_path = '/content/drive/MyDrive/Models'"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfAIJjr-QZ-E"
      },
      "source": [
        "# function to design CNN architecture which is then compiled and trained. returns trained model and predictions on test data.\n",
        "def design_CNN_softmax(model, model_name):\n",
        "  '''\n",
        "  function: inputs number of CNN architecture layers to be defined and defines each layer\n",
        "            with corresponding parameters. model is trained, compiled and saved in drive folder.\n",
        "  param: data type of model , name of model defined by user\n",
        "  returns: trained model, predictions\n",
        "  '''\n",
        "\n",
        "  img_size = 32\n",
        "  channels = 3\n",
        "  num_classes = 43\n",
        "  layer_num = 1\n",
        "\n",
        "  total_layers = int(input('Enter the total number of layers of the architecture:'))\n",
        "\n",
        "  while (total_layers !=0):\n",
        "    total_layers -= 1\n",
        "\n",
        "    add = str(input('Enter the type of layer:'))\n",
        "    if add == 'Conv2D':\n",
        "\n",
        "      if layer_num != 1:\n",
        "\n",
        "          filters = int(input('Enter filter size: recommended-16, 32, 64, 128, 256, 512:'))\n",
        "          kernel_size = tuple(map(int, input('Enter kernel size:').split(',')))\n",
        "          strides = tuple(map(int, input('Enter strides:').split(',')))\n",
        "          padding = input('Enter type of padding:')\n",
        "          activation = str(input('Enter the activation function:'))\n",
        "\n",
        "          model.add(Conv2D(filters, kernel_size, strides, padding, activation = activation))\n",
        "          layer_num += 1\n",
        "        \n",
        "      else:\n",
        "          filters = int(input('Enter filter size: recommended-16, 32, 64, 128, 256, 512:'))\n",
        "          kernel_size = tuple(map(int, input('Enter kernel size:').split(',')))\n",
        "          strides = tuple(map(int, input('Enter strides:').split(',')))\n",
        "          padding = str(input('Enter type of padding:'))\n",
        "          activation = str(input('Enter the activation function:'))\n",
        "\n",
        "          input_shape = (img_size, img_size, channels)\n",
        "          model.add(Conv2D(filters, kernel_size, strides, padding, activation = activation, input_shape = input_shape))\n",
        "          layer_num += 1\n",
        "\n",
        "    elif add == 'MaxPool2D':\n",
        "        pool_size = tuple(map(int, input('Enter pool size:').split(',')))\n",
        "        strides = tuple(map(int, input('Enter strides:').split(',')))\n",
        "        padding = str(input('Enter type of padding:'))\n",
        "\n",
        "        model.add(MaxPool2D(pool_size, strides, padding))\n",
        "        layer_num += 1\n",
        "\n",
        "    elif add == 'Flatten': \n",
        "        model.add(Flatten())\n",
        "        layer_num += 1\n",
        "\n",
        "    elif add == 'Dense':\n",
        "        units = int(input('Enter number of dense layer units:'))\n",
        "        activation = str(input('Enter the activation function:'))\n",
        "\n",
        "        model.add(Dense(units, activation))\n",
        "        layer_num += 1\n",
        "\n",
        "    elif add == 'BatchNormalization': \n",
        "        model.add(BatchNormalization())\n",
        "        layer_num += 1\n",
        "\n",
        "    elif add == 'Dropout': \n",
        "        rate = float(input('Enter dropout value:'))\n",
        "\n",
        "        model.add(Dropout(rate = rate))\n",
        "        layer_num += 1\n",
        "\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(rate=0.5))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "  print('Model architecture has been defined.')\n",
        "\n",
        "  optimizer = str(input('Choose Optimizer:'))\n",
        "\n",
        "  if optimizer in optimizers:\n",
        "    if optimizer == 'SGD':\n",
        "\n",
        "      tuning = input('Do you want to tune optimizer hyperparameters? (y/n)')\n",
        "\n",
        "      if tuning == 'y':\n",
        "        learning_rate = float(input('Enter learning rate:'))\n",
        "        momentum = float(input('Enter momentum value:'))\n",
        "\n",
        "        opt = keras.optimizers.SGD(learning_rate, momentum)\n",
        "\n",
        "      else:\n",
        "        opt = keras.optimizers.SGD()\n",
        "\n",
        "    elif optimizer == 'RMSprop':\n",
        "\n",
        "      tuning = input('Do you want to tune optimizer hyperparameters? (y/n)')\n",
        "\n",
        "      if tuning == 'y':\n",
        "        learning_rate = float(input('Enter learning rate:'))\n",
        "        momentum = float(input('Enter momentum value:'))\n",
        "        rho = float(input('Enter value:'))\n",
        "        epsilon = float(input('Enter epsilon value:'))\n",
        "\n",
        "        opt = keras.optimizers.RMSprop(learning_rate, rho, momentum, epsilon)\n",
        "      else:\n",
        "        opt = keras.optimizers.RMSprop()\n",
        "\n",
        "    \n",
        "    elif optimizer == 'Adam':\n",
        "      tuning = input('Do you want to tune optimizer hyperparameters? (y/n)')\n",
        "\n",
        "      if tuning == 'y':\n",
        "        learning_rate = float(input('Enter learning rate:'))\n",
        "        beta_1 = float(input('Enter beta_1 value:'))\n",
        "        beta_2 = float(input('Enter beta_1 value:'))\n",
        "        epsilon = float(input('Enter epsilon value:'))\n",
        "\n",
        "        opt = keras.optimizers.Adam(learning_rate, beta_1, beta_2, epsilon=1e-07)\n",
        "\n",
        "      else:\n",
        "        opt = keras.optimizers.Adam()\n",
        "\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  X_train, Y_train = load_train_data()\n",
        "  X_test, Y_test = load_test_data()\n",
        "  batch_size = int(input('Enter batch size:'))\n",
        "  epochs = int(input('Enter number of epochs:'))\n",
        "\n",
        "  model.fit(X_train, Y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=(X_test, Y_test),\n",
        "            shuffle=True,)\n",
        "  \n",
        "  model.save(model_path+'/' + model_name + '.hdf5')\n",
        "  predictions = model.evaluate(X_test, Y_test)\n",
        "\n",
        "  return model, predictions"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2VLHYUBXxHM"
      },
      "source": [
        "# Function to Design CNN + Classifier \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bQm0pE7mRKJ"
      },
      "source": [
        "# dropdown of available classifiers\n",
        "classifiers = ['Decision tree', 'SVC', 'KNN', 'Random Forest' ]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbEVOyuxmRbU"
      },
      "source": [
        "def design_CNN_classifier(model_name):\n",
        "  '''\n",
        "  function: uses design_CNN_softmax function to train model. Inputs classifier which is used for final prediction. Saves model and classifier in drive folder.\n",
        "  param: name of model defined by user\n",
        "  returns: trained model, accuracy, trained classifier\n",
        "  '''\n",
        "\n",
        "  model = Sequential()\n",
        "  model, predictions = design_CNN_softmax(model, model_name)\n",
        "\n",
        "  n = len(model.layers)\n",
        "  getFeature = K.function([model.layers[0].input],\n",
        "                        [model.layers[n-2].output])\n",
        "  \n",
        "  X_train, Y_train = load_train_data()\n",
        "  X_test, Y_test = load_test_data()\n",
        "\n",
        "  test = getFeature([X_test])[0]\n",
        "  Y_test = np.argmax(Y_test, axis = 1)\n",
        "  train = getFeature([X_train])[0]\n",
        "  Y_train = np.argmax(Y_train, axis = 1)\n",
        "\n",
        "  classifier = str(input('choose classfier for final image classification:'))\n",
        "\n",
        "  if classifier == 'SVC':\n",
        "    classifier = SVC()\n",
        "    classifier.fit(train, Y_train)\n",
        "\n",
        "  elif classifier == 'KNN':\n",
        "    classifier = KNeighborsClassifier()\n",
        "    classifier.fit(train, Y_train)\n",
        "\n",
        "  elif classifier == 'Decision Tree':\n",
        "    classifier = DecisionTreeClassifier()\n",
        "    classifier.fit(train, Y_train)\n",
        "\n",
        "  elif classifier == 'Random Forest':\n",
        "    classifier = RandomForestClassifier ()\n",
        "    classifier.fit(train, Y_train)\n",
        "\n",
        "  accuracy = classifier.score(test, Y_test)\n",
        "\n",
        "  %cd '/content/drive/MyDrive/Models'\n",
        "  pkl_filename = model_name + '.pkl'\n",
        "  with open(pkl_filename, 'wb') as file:\n",
        "    pickle.dump(classifier, file)\n",
        "  %cd '/content/drive'\n",
        "\n",
        "  return model, accuracy, classifier"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd5gHmOZX8h5"
      },
      "source": [
        "# Function for Pre-Trained + softmax \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqF0nRmdcMQN"
      },
      "source": [
        "pre_trained_models = ['ResNet50', 'VGG16', 'VGG19', 'InceptionV3', 'Xception']"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STQO9GeKb0GC"
      },
      "source": [
        "def pre_trained_softmax(model, model_name):\n",
        "  '''\n",
        "  function: inputs pre-trained model and optimizer. model is trained, compiled, fitted and saved\n",
        "  param: type of model and name of model defined by user\n",
        "  returns: trained model and prediction\n",
        "  '''\n",
        "\n",
        "  img_size = 32\n",
        "  channels = 3\n",
        "  num_classes = 43\n",
        "  input_shape = (img_size, img_size, channels)\n",
        "  x = str(input('Choose your pre-trained model:'))\n",
        "  \n",
        "  if x == 'ResNet50':\n",
        "    model.add(ResNet50(include_top = False, weights = 'imagenet', input_shape = (img_size, img_size, channels)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(rate=0.5))\n",
        "    model.add(Dense(num_classes, activation = 'softmax'))\n",
        "    model.layers[0].trainable = False\n",
        "    \n",
        "  elif x == 'VGG16':\n",
        "    model.add(VGG16(include_top = False, weights = 'imagenet', input_shape = (img_size, img_size, channels)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(rate=0.5))\n",
        "    model.add(Dense(num_classes, activation = 'softmax'))\n",
        "    model.layers[0].trainable = False\n",
        "\n",
        "  elif x == 'VGG19':\n",
        "    model.add(VGG19(include_top = False, weights = 'imagenet', input_shape = (img_size, img_size, channels)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(rate=0.5))\n",
        "    model.add(Dense(num_classes, activation = 'softmax'))\n",
        "    model.layers[0].trainable = False\n",
        "\n",
        "  elif x == 'InceptionV3':\n",
        "    model.add(InceptionV3(include_top = False, weights = 'imagenet', input_shape = (img_size, img_size, channels)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(rate=0.5))\n",
        "    model.add(Dense(num_classes, activation = 'softmax'))\n",
        "    model.layers[0].trainable = False\n",
        "\n",
        "  elif x == 'Xception':\n",
        "    model.add(Xception(include_top = False, weights = 'imagenet', input_shape = (img_size, img_size, channels)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(rate=0.5))\n",
        "    model.add(Dense(num_classes, activation = 'softmax'))\n",
        "    model.layers[0].trainable = False\n",
        "\n",
        "  optimizer = str(input('Choose Optimizer:'))\n",
        "\n",
        "  if optimizer in optimizers:\n",
        "    if optimizer == 'SGD':\n",
        "\n",
        "      tuning = input('Do you want to tune optimizer hyperparameters? (y/n)')\n",
        "\n",
        "      if tuning == 'y':\n",
        "        learning_rate = float(input('Enter learning rate:'))\n",
        "        momentum = float(input('Enter momentum value:'))\n",
        "\n",
        "        opt = keras.optimizers.SGD(learning_rate, momentum)\n",
        "\n",
        "      else:\n",
        "        opt = keras.optimizers.SGD()\n",
        "\n",
        "    elif optimizer == 'RMSprop':\n",
        "\n",
        "      tuning = input('Do you want to tune optimizer hyperparameters? (y/n)')\n",
        "\n",
        "      if tuning == 'y':\n",
        "        learning_rate = float(input('Enter learning rate:'))\n",
        "        momentum = float(input('Enter momentum value:'))\n",
        "        rho = float(input('Enter value:'))\n",
        "        epsilon = float(input('Enter epsilon value:'))\n",
        "\n",
        "        opt = keras.optimizers.RMSprop(learning_rate, rho, momentum, epsilon)\n",
        "      else:\n",
        "        opt = keras.optimizers.RMSprop()\n",
        "\n",
        "    \n",
        "    elif optimizer == 'Adam':\n",
        "      tuning = input('Do you want to tune optimizer hyperparameters? (y/n)')\n",
        "\n",
        "      if tuning == 'y':\n",
        "        learning_rate = float(input('Enter learning rate:'))\n",
        "        beta_1 = float(input('Enter beta_1 value:'))\n",
        "        beta_2 = float(input('Enter beta_1 value:'))\n",
        "        epsilon = float(input('Enter epsilon value:'))\n",
        "\n",
        "        opt = keras.optimizers.Adam(learning_rate, beta_1, beta_2, epsilon=1e-07)\n",
        "\n",
        "      else:\n",
        "        opt = keras.optimizers.Adam()\n",
        "\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  X_train, Y_train = load_train_data()\n",
        "  X_test, Y_test = load_test_data()\n",
        "  batch_size = int(input('Enter batch size:'))\n",
        "  epochs = int(input('Enter number of epochs:'))\n",
        "\n",
        "  model.fit(X_train, Y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=(X_test, Y_test),\n",
        "            shuffle=True,)\n",
        "  \n",
        "  model.save(model_path + '/' + model_name + '.hdf5')\n",
        "  predictions = model.predict(X_test)\n",
        "\n",
        "  return model, predictions"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZYnzRg0YHL8"
      },
      "source": [
        "# Function for Pre-trained + Classifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqboPuHRbewE"
      },
      "source": [
        "# def pre_trained_classifier(model_name):\n",
        "#   '''\n",
        "#   function:\n",
        "#   param:\n",
        "#   returns:\n",
        "#   '''\n",
        "#   model = Sequential()\n",
        "#   model, predictions = pre_trained_softmax(model, model_name)\n",
        "\n",
        "#   n = len(model.layers)\n",
        "#   getFeature = K.function([model.layers[0].input],\n",
        "#                         [model.layers[n-2].output])\n",
        "  \n",
        "#   X_train, Y_train = load_train_data()\n",
        "#   X_test, Y_test = load_test_data()\n",
        "\n",
        "#   test = getFeature([X_test])[0]\n",
        "#   Y_test = np.argmax(Y_test, axis = 1)\n",
        "#   train = getFeature([X_train])[0]\n",
        "#   Y_train = np.argmax(Y_train, axis = 1)\n",
        "\n",
        "#   classifier = str(input('choose classfier for final image classification:'))\n",
        "\n",
        "#   if classifier == 'SVC':\n",
        "#     classifier = SVC()\n",
        "#     classifier.fit(train, Y_train)\n",
        "\n",
        "#   elif classifier == 'KNN':\n",
        "#     classifier = KNeighborsClassifier()\n",
        "#     classifier.fit(train, Y_train)\n",
        "\n",
        "#   elif classifier == 'Decision Tree':\n",
        "#     classifier = DecisionTreeClassifier()\n",
        "#     classifier.fit(train, Y_train)\n",
        "\n",
        "#   elif classifier == 'Random Forest':\n",
        "#     classifier = RandomForestClassifier ()\n",
        "#     classifier.fit(train, Y_train)\n",
        "\n",
        "#   accuracy = classifier.score(test, Y_test)\n",
        "\n",
        "#   %cd '/content/drive/MyDrive/Models'\n",
        "#   pkl_filename = model_name + '.pkl'\n",
        "#   with open(pkl_filename, 'wb') as file:\n",
        "#     pickle.dump(classifier, file)\n",
        "#   %cd '/content/drive'\n",
        "\n",
        "#   return model, accuracy, classifier"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUjDi_goYPvR"
      },
      "source": [
        "# Function of our Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cTBBkP7be26"
      },
      "source": [
        "def my_model():\n",
        "  '''\n",
        "  function: loads pre-trained model from drive\n",
        "  param:\n",
        "  returns: predictions\n",
        "  '''\n",
        "  path = '/content/drive/MyDrive/GTSRB_classification.h5'\n",
        "  X_test, Y_test = load_test_data()\n",
        "\n",
        "  loaded_model = load_model(path)\n",
        "  y_pred = loaded_model.evaluate(X_test, Y_test)\n",
        "\n",
        "  loaded_model.save(model_path+'/' + os.path.basename(os.path.normpath(path)))\n",
        "\n",
        "  return y_pred"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7sbxxfyYY2N"
      },
      "source": [
        "# Choose Types of Models to be trained on\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLqQFZ_rqRyb"
      },
      "source": [
        "def model_to_be_trained(m):\n",
        "  '''\n",
        "  function: calls the functions defined earlier to define a model as per user choice\n",
        "  param: number of models to be trained\n",
        "  returns: dictionary of trained models with corresponding accuracy\n",
        "  '''\n",
        "\n",
        "  models_dict={}\n",
        "\n",
        "  while(m!=0):\n",
        "\n",
        "    choice = str(input('Select the type of model do you want to train on:'))\n",
        "\n",
        "    if choice == 'design CNN architecture + softmax':\n",
        "      model_name = str(input('Enter the name of your model:'))\n",
        "\n",
        "      model = Sequential()\n",
        "      trained_model, prediction = design_CNN_softmax(model, model_name)\n",
        "\n",
        "      models_dict[model_name]=prediction[1]\n",
        "\n",
        "    if choice == 'design CNN architecture + classifiers':\n",
        "      model_name = str(input('Enter the name of your model:'))\n",
        "\n",
        "      model, accuracy, classifier = design_CNN_classifier(model_name)\n",
        "\n",
        "      models_dict[model_name]=accuracy\n",
        "\n",
        "    if choice == 'use pre-trained models + softmax':\n",
        "      model_name = str(input('Enter the name of your model:'))\n",
        "\n",
        "      model = Sequential()\n",
        "      model, prediction = pre_trained_softmax(model, model_name)\n",
        "      \n",
        "      models_dict[model_name]=prediction[1]\n",
        "\n",
        "    # if choice == 'use pre-trained + classifiers':\n",
        "    #   model_name = str(input('Enter the name of your model:'))\n",
        "\n",
        "    #   model, accuracy, classifier = pre_trained_classifier(model_name)\n",
        "      \n",
        "    #   models_dict[model_name]=accuracy\n",
        "\n",
        "    if choice == 'trained model':\n",
        "      pred = my_model()\n",
        "      models_dict['GTSRB_classification']=pred[1]\n",
        "\n",
        "  return models_dict"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HuoNJ1uZT3E"
      },
      "source": [
        "options = ['design CNN architecture + softmax', \n",
        "           'design CNN architecture + classifiers',\n",
        "           'use pre-trained models + softmax', \n",
        "          #  'use pre-trained + classifiers',\n",
        "           'trained model']\n",
        "\n",
        "m = int(input('choose the number of models to be trained'))\n",
        "models_dict = model_to_be_trained(m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnGvGFjic4Y4"
      },
      "source": [
        "# Ensemble Function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb3tmn-Fcqm8"
      },
      "source": [
        "no_of_models = int(input('Enter no of models'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKs3W6J15A2N"
      },
      "source": [
        "def ensemble(no_of_models):\n",
        "  '''\n",
        "  function: ensembles tope accuracy models\n",
        "  param: number of models to create ensemble with\n",
        "  returns: mean accuracy after ensembling, number of models used for ensembling\n",
        "  '''\n",
        "  sorted_tuples = sorted(models_dict.items(), key=lambda item: item[1])\n",
        "  sorted_dict = {k: v for k, v in sorted_tuples}\n",
        "  models=[]\n",
        "  acc=[]\n",
        "  for k,v in sorted_dict.items():\n",
        "    models.append(k)\n",
        "    acc.append(v)\n",
        "  acc_mean=np.mean(acc[0:no_of_models])   \n",
        "  models_used=models[0:no_of_models]\n",
        "  return acc_mean, models_used"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2ByozOc5BOX"
      },
      "source": [
        "models_to_ensemble=[]\n",
        "no_of_models=int(input('Enter no of models'))\n",
        "for i in range(0, no_of_models): \n",
        "    model = input('Enter the model name') \n",
        "    models_to_ensemble.append(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snHTB1o5cqrJ"
      },
      "source": [
        "def ensemble(models_list):\n",
        "  '''\n",
        "  function: ensembles models as per user choice\n",
        "  param: list of models to be ensembled\n",
        "  returns: mean accuracy after ensembling\n",
        "  '''\n",
        "  sorted_tuples = sorted(models_dict.items(), key=lambda item: item[1])\n",
        "  sorted_dict = {k: v for k, v in sorted_tuples}\n",
        "  acc=[]\n",
        "  for i in models_list:\n",
        "    acc.append(sorted_dict[i])\n",
        "  mean_acc=np.mean(acc)\n",
        "  return mean_acc  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}